{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac326b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11805d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'D:\\data\\benchmark\\cora'\n",
    "\n",
    "label_dict = {'Case_Based':0,\n",
    "              'Genetic_Algorithms':1,\n",
    "              'Neural_Networks':2,\n",
    "              'Probabilistic_Methods':3,\n",
    "              'Reinforcement_Learning':4,\n",
    "              'Rule_Learning':5,\n",
    "              'Theory':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8906b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_data(data_path:str,\n",
    "                   label_dict:Dict[str,int]=label_dict,\n",
    "                   train_size: float=1.0,\n",
    "                   val_size: float=0.0,\n",
    "                   test_size: float=0.0,\n",
    "                   random_seed: int=42)->torch_geometric.data.Data:\n",
    "        \n",
    "    '''\n",
    "    :param data_path: cora data path\n",
    "    :param label_dict: cora data label\n",
    "    :param train_size: train sample size\n",
    "    :param val_size: validation sample size\n",
    "    :param test_size: test sample size\n",
    "    :param random_seed: random seed\n",
    "    \n",
    "    :return: torch_geometric data\n",
    "    '''\n",
    "    \n",
    "    # load edges\n",
    "    with open(os.path.join(data_path, 'cora.cites')) as f:\n",
    "        cites = f.readlines()\n",
    "    # load node features\n",
    "    with open(os.path.join(data_path, 'cora.content')) as f:\n",
    "        contents = f.readlines()\n",
    "    \n",
    "    cites = sorted([list(map(int,i.strip().split('\\t'))) for i in cites])\n",
    "    contents_preprocessed = []\n",
    "    for doc in contents:\n",
    "        doc_preprocessed = []\n",
    "        doc_split = doc.strip().split('\\t')\n",
    "        for idx, token in enumerate(doc_split):\n",
    "            if idx < len(doc_split)-1:\n",
    "                doc_preprocessed.append(int(token))\n",
    "            else:\n",
    "                label = label_dict.get(token)\n",
    "                doc_preprocessed.append(label)\n",
    "\n",
    "        contents_preprocessed.append(doc_preprocessed)\n",
    "\n",
    "    contents = sorted(contents_preprocessed, key=lambda x: x[0])\n",
    "    \n",
    "    id_unique = set([i[0] for i in contents])\n",
    "    id_map = {a:i for i,a in enumerate(sorted(list(id_unique)))}\n",
    "    \n",
    "    cites_num = 0\n",
    "    node_features, node_labels, edges = [], [], []\n",
    "    \n",
    "    for idx,content in enumerate(contents):\n",
    "\n",
    "        paper_id = content[0]\n",
    "        # first value = paper id, last value = class label\n",
    "        doc_attrs = content[1:-1]\n",
    "        class_label = content[-1]\n",
    "        \n",
    "        while paper_id != cites[cites_num][0]:\n",
    "            \n",
    "            edge_pair = []\n",
    "            edge_pair.append(id_map.get(cites[cites_num][0]))\n",
    "            edge_pair.append(id_map.get(cites[cites_num][1]))\n",
    "            edges.append(edge_pair)\n",
    "            # undirected\n",
    "            edge_pair = []\n",
    "            edge_pair.append(id_map.get(cites[cites_num][1]))\n",
    "            edge_pair.append(id_map.get(cites[cites_num][0]))\n",
    "            edges.append(edge_pair)\n",
    "            # break loop\n",
    "            if cites_num == len(cites)-1:\n",
    "                break\n",
    "            cites_num += 1\n",
    "        \n",
    "        node_features.append(doc_attrs)\n",
    "        node_labels.append(class_label)\n",
    "    \n",
    "    # train, val, test split\n",
    "    total_nodes = list(range(len(contents)))\n",
    "    random.seed(random_seed)\n",
    "    random.shuffle(total_nodes)\n",
    "    train_idx, val_idx, test_idx = np.split(total_nodes, \n",
    "                                            [int(train_size*len(total_nodes)), \n",
    "                                             int((train_size+val_size)*len(total_nodes))])\n",
    "        \n",
    "    data = torch_geometric.data.Data(x=torch.tensor(node_features, dtype=torch.float),\n",
    "                                     y=torch.tensor(node_labels, dtype=torch.long),\n",
    "                                     edge_index=torch.tensor(torch.tensor(edges)).T,\n",
    "                                     train_idx=train_idx,\n",
    "                                     val_idx=val_idx,\n",
    "                                     test_idx=test_idx)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "379b6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim: int, \n",
    "                 hidden_dim: int, \n",
    "                 output_dim: int, \n",
    "                 training: bool):\n",
    "        super(GCNModel, self).__init__()\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(self.build_conv_model(input_dim, hidden_dim))\n",
    "        self.lns = nn.ModuleList()\n",
    "        for l in range(1):\n",
    "            self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        self.training = training\n",
    "        \n",
    "        for l in range(2):\n",
    "            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
    "            \n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "        \n",
    "        self.dropout = 0.3\n",
    "        self.num_layers = 2\n",
    "        \n",
    "    def build_conv_model(self,\n",
    "                         input_dim: int,\n",
    "                         hidden_dim: int):\n",
    "        return GCNConv(input_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, \n",
    "                data: torch_geometric.data.Data):\n",
    "        \n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        if data.num_node_features == 0:\n",
    "            x = torch.ones(data.num_nodes, 1)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p = self.dropout, training=self.training)\n",
    "            if not i == self.num_layers - 1:\n",
    "                x = self.lns[i](x)\n",
    "        \n",
    "        \n",
    "        x = self.post_mp(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def loss(self, pred, label):\n",
    "        return F.cross_entropy(pred, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeaf8fb",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b92eea8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train loss : 1.90685487\n",
      "Epoch 2 train loss : 1.78706861\n",
      "Epoch 3 train loss : 1.71203530\n",
      "Epoch 4 train loss : 1.62397397\n",
      "Epoch 5 train loss : 1.53358936\n",
      "===============================\n",
      "Epoch 5 validation loss : 1.3484\n",
      "Epoch 5 f1 score : 0.4557\n",
      "===============================\n",
      "Epoch 6 train loss : 1.32751226\n",
      "Epoch 7 train loss : 1.20975363\n",
      "Epoch 8 train loss : 1.09696209\n",
      "Epoch 9 train loss : 0.98926634\n",
      "Epoch 10 train loss : 0.88467997\n",
      "===============================\n",
      "Epoch 10 validation loss : 0.8269\n",
      "Epoch 10 f1 score : 0.8247\n",
      "===============================\n",
      "Epoch 11 train loss : 0.78524959\n",
      "Epoch 12 train loss : 0.69512892\n",
      "Epoch 13 train loss : 0.61588442\n",
      "Epoch 14 train loss : 0.54536206\n",
      "Epoch 15 train loss : 0.48194444\n",
      "===============================\n",
      "Epoch 15 validation loss : 0.4872\n",
      "Epoch 15 f1 score : 0.8764\n",
      "===============================\n",
      "Epoch 16 train loss : 0.42626092\n",
      "Epoch 17 train loss : 0.37861359\n",
      "Epoch 18 train loss : 0.33798730\n",
      "Epoch 19 train loss : 0.30307183\n",
      "Epoch 20 train loss : 0.27289969\n",
      "===============================\n",
      "Epoch 20 validation loss : 0.3538\n",
      "Epoch 20 f1 score : 0.8948\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "data = construct_data(data_path, train_size=0.7, val_size=0.2, test_size=0.1)\n",
    "total_size = data.x.shape[0]\n",
    "train_size = len(data.train_idx)\n",
    "val_size = len(data.val_idx)\n",
    "# input dim : dimension of node features\n",
    "model = GCNModel(input_dim=1433, hidden_dim=128, output_dim=7, training=True).to(device)\n",
    "\n",
    "train_dataloader = torch_geometric.loader.DataLoader([data],batch_size=total_size,shuffle=True)\n",
    "val_dataloader = torch_geometric.loader.DataLoader([data],batch_size=total_size,shuffle=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(20):\n",
    "    epoch_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i,train_batch in enumerate(train_dataloader):\n",
    "        train_batch = train_batch.to(device)\n",
    "        pred = model(train_batch)\n",
    "        label = train_batch.y\n",
    "        loss = model.loss(pred[data.train_idx], label[data.train_idx])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print('Epoch {} train loss : {:.8f}'.format(epoch+1, epoch_loss))\n",
    "    \n",
    "    if (epoch+1)%5==0:\n",
    "        model.eval()\n",
    "        for i,val_batch in enumerate(val_dataloader):\n",
    "            val_batch = val_batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(val_batch)\n",
    "                label = val_batch.y\n",
    "                loss = model.loss(pred[data.val_idx], label[data.val_idx])\n",
    "                model_score = f1_score(y_true = label[data.val_idx],\n",
    "                                       y_pred = pred.argmax(1)[data.val_idx],\n",
    "                                       average = 'micro')\n",
    "        print('===============================')\n",
    "        print('Epoch {} validation loss : {:.4f}'.format(epoch+1, loss.item()))\n",
    "        print('Epoch {} f1 score : {:.4f}'.format(epoch+1, model_score))\n",
    "        print('===============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d5a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon_molecule",
   "language": "python",
   "name": "dacon_molecule"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
